{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ryanp\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ryanp\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ryanp\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\ryanp\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ryanp\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.3360 - accuracy: 0.9034\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1340 - accuracy: 0.9606\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9714\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0685 - accuracy: 0.9793\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0561 - accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1db19e1d950>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def testMLP(x_train, y_train, x_test, y_test):\n",
    "# Preprocess the data\n",
    "x_train = x_train.reshape(-1, 784) / 255.0\n",
    "x_test = x_test.reshape(-1, 784) / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(784,)),\n",
    "    Dense(128, activation='relu'),  # 128 neurons in the first hidden layer\n",
    "    Dense(64, activation='relu'),  # 64 neurons in the second hidden layer\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronActivationComputer:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def compute_activations(self, x_test, y_test):\n",
    "        num_classes = y_test.shape[-1]\n",
    "\n",
    "        # Get the layer outputs for the test data\n",
    "        layer_outputs = []\n",
    "        for layer in self.model.layers:\n",
    "            if hasattr(layer, 'output'):\n",
    "                layer_model = tf.keras.Model(inputs=self.model.input, outputs=layer.output)\n",
    "                layer_outputs.append(layer_model.predict(x_test))\n",
    "\n",
    "        # Compute the neuron activations averaged for each label and each layer\n",
    "        layer_activations = []\n",
    "        for outputs in layer_outputs:\n",
    "            num_neurons_in_layer = outputs.shape[-1]\n",
    "            layer_activation = np.zeros((num_classes, num_neurons_in_layer))\n",
    "            for label_idx in range(num_classes):\n",
    "                layer_activation[label_idx] = np.mean(outputs[np.argmax(y_test, axis=1) == label_idx], axis=0)\n",
    "            layer_activations.append(layer_activation)\n",
    "\n",
    "        return layer_activations\n",
    "\n",
    "    def visualize_activations(self, layer_idx, class_idx=None):\n",
    "        layer_activations = self.compute_activations(x_test, y_test)\n",
    "        activations = layer_activations[layer_idx]\n",
    "\n",
    "        if class_idx is None:\n",
    "            # Visualize activations for all classes\n",
    "            fig, axs = plt.subplots(2, 5, figsize=(15, 10))\n",
    "            axs = axs.flatten()  # Flatten the array of axes to easily iterate over it\n",
    "\n",
    "            for class_label, class_activations in enumerate(activations):\n",
    "                # Convert activations to numpy array for plotting\n",
    "                class_activations = np.array(class_activations)\n",
    "\n",
    "                # Create a bar plot for the activations\n",
    "                axs[class_label].bar(range(len(class_activations)), class_activations)\n",
    "                axs[class_label].set_title(f'Activations for Class {class_label}')\n",
    "                axs[class_label].set_xlabel('Activation Index')\n",
    "                axs[class_label].set_ylabel('Activation Value')\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            # Visualize activations for a specific class\n",
    "            print(f\"Class {class_idx}:\")\n",
    "            print(activations[class_idx])\n",
    "\n",
    "    def visualize_activations_for_neuron(self, layer_idx, neuron_idx):\n",
    "        layer_activations = self.compute_activations(x_test, y_test)\n",
    "        activations = layer_activations[layer_idx]\n",
    "\n",
    "        # Visualize the activations for the specified neuron\n",
    "        neuron_activations = [class_activations[neuron_idx] for class_activations in activations]\n",
    "        plt.bar(range(len(neuron_activations)), neuron_activations)\n",
    "        plt.title(f'Activations for Neuron {neuron_idx}')\n",
    "        plt.xlabel('Class Index')\n",
    "        plt.ylabel('Activation Value')\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_activations_for_layer(self):\n",
    "        layer_outputs = []\n",
    "        for layer in model.layers:\n",
    "            if hasattr(layer, 'output'):\n",
    "                layer_model = tf.keras.Model(inputs=model.input, outputs=layer.output)\n",
    "                layer_outputs.append(layer_model.predict(x_test))\n",
    "\n",
    "        # Compute the neuron activations averaged for each label and each layer\n",
    "        layer_activations = []\n",
    "        for outputs in layer_outputs:\n",
    "            num_neurons_in_layer = outputs.shape[-1]\n",
    "            layer_activation = np.zeros((num_classes, num_neurons_in_layer))\n",
    "            for label_idx in range(num_classes):\n",
    "                layer_activation[label_idx] = np.mean(outputs[np.argmax(y_test, axis=1) == label_idx], axis=0)\n",
    "            layer_activations.append(layer_activation)\n",
    "\n",
    "        # Visualize the activations for each layer\n",
    "        for layer in layer_activations:\n",
    "            plt.figure(figsize=(5, 12))  # Set the initial figure size\n",
    "            plt.matshow(layer, cmap='hot', interpolation='nearest', aspect=20)\n",
    "            plt.gcf().set_figheight(5)\n",
    "            plt.gcf().set_figwidth(30)\n",
    "            plt.show() \n",
    "        # fig, axs = plt.subplots(4, 1, figsize=(30, 60))\n",
    "        \n",
    "        # for i, layer in enumerate(layer_activations):\n",
    "        #     im = axs[i].matshow(layer, cmap='hot', interpolation='nearest', aspect=20)\n",
    "        #     axs[i].set_title(f'Layer {i+1} Activations')\n",
    "\n",
    "        # # Add a colorbar to the figure\n",
    "        # fig.colorbar(im, ax=axs.ravel().tolist(), orientation='horizontal', pad=0.02)\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "    def analyze_activations(self, layer_idx, analysis_function):\n",
    "        layer_activations = self.compute_activations(x_test, y_test)\n",
    "        activations = layer_activations[layer_idx]\n",
    "\n",
    "        # Apply the analysis function to the activations\n",
    "        analysis_result = analysis_function(activations)\n",
    "\n",
    "        return analysis_result\n",
    "    \n",
    "# crate an instance of the NeuronActivationComputer class\n",
    "neuron_activation_computer = NeuronActivationComputer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n",
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Visualize the activations of the first hidden layer\n",
    "# neuron_activation_computer.visualize_activations(0)\n",
    "# neuron_activation_computer.visualize_activations_for_neuron(2, 50)\n",
    "neuron_activation_computer.visualize_activations_for_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the layer outputs for the test data\n",
    "layer_outputs = []\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'output'):\n",
    "        layer_model = tf.keras.Model(inputs=model.input, outputs=layer.output)\n",
    "        layer_outputs.append(layer_model.predict(x_test))\n",
    "\n",
    "# Compute the neuron activations averaged for each label\n",
    "num_layers = len(layer_outputs)\n",
    "num_neurons = sum(outputs.shape[-1] for outputs in layer_outputs)\n",
    "neuron_activations = np.zeros((num_classes, num_neurons))\n",
    "\n",
    "for label_idx in range(num_classes):\n",
    "    label_test_data = x_test[np.argmax(y_test, axis=1) == label_idx]\n",
    "    label_activations = np.zeros((num_neurons,))\n",
    "    neuron_idx = 0\n",
    "    for j, outputs in enumerate(layer_outputs):\n",
    "        num_neurons_in_layer = outputs.shape[-1]\n",
    "        label_activations[neuron_idx:neuron_idx + num_neurons_in_layer] = np.mean(outputs[np.argmax(y_test, axis=1) == label_idx], axis=0)\n",
    "        neuron_idx += num_neurons_in_layer\n",
    "    neuron_activations[label_idx] = label_activations\n",
    "\n",
    "# Print the neuron activations matrix\n",
    "print(neuron_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neuron_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the matrix\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 12))  # Set the initial figure size\n",
    "plt.matshow(neuron_activations, cmap='hot', interpolation='nearest', aspect=20)\n",
    "plt.gcf().set_figheight(12)\n",
    "plt.gcf().set_figwidth(30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the layer outputs for EVERY LAYER as a 2dmatrix in list the test data\n",
    "layer_outputs = []\n",
    "for layer in model.layers:\n",
    "    if hasattr(layer, 'output'):\n",
    "        layer_model = tf.keras.Model(inputs=model.input, outputs=layer.output)\n",
    "        layer_outputs.append(layer_model.predict(x_test))\n",
    "\n",
    "# Compute the neuron activations averaged for each label and each layer\n",
    "layer_activations = []\n",
    "for outputs in layer_outputs:\n",
    "    num_neurons_in_layer = outputs.shape[-1]\n",
    "    layer_activation = np.zeros((num_classes, num_neurons_in_layer))\n",
    "    for label_idx in range(num_classes):\n",
    "        layer_activation[label_idx] = np.mean(outputs[np.argmax(y_test, axis=1) == label_idx], axis=0)\n",
    "    layer_activations.append(layer_activation)\n",
    "\n",
    "# Print the neuron activations matrix for each layer\n",
    "# for i, layer_activation in enumerate(layer_activations):\n",
    "#     print(f\"Layer {i} neuron activations:\")\n",
    "#     print(layer_activation)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for layer in layer_activations:\n",
    "    plt.figure(figsize=(12, 12))  # Set the initial figure size\n",
    "    plt.matshow(layer, cmap='hot', interpolation='nearest', aspect=20)\n",
    "    plt.gcf().set_figheight(12)\n",
    "    plt.gcf().set_figwidth(30)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I am going o go on a side track. Here my vision is to create a \"Phantom 4\" Where I perform data augmentation to remove the stalks from the 4s and then prove that I can sill recover the 4s with high accuracy using the ablation to elarn the stalk identification fromt the mean activation using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(layer_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am going to graph the initial 4 activation before I start\n",
    "just_4 = []\n",
    "just_7 = []\n",
    "\n",
    "max_len = max(len(layer) for layer in layer_activations)  # Find the maximum length\n",
    "\n",
    "for layer in layer_activations:\n",
    "    padded_layer = np.pad(layer, (0, max_len - len(layer)), 'constant', constant_values=0)  # Pad the layer\n",
    "    just_4.append(padded_layer[4])\n",
    "    just_7.append(padded_layer[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum length of any list in just_4\n",
    "max_len = max(len(lst) for lst in just_4)\n",
    "\n",
    "# Pad each list in just_4 to make them the same length\n",
    "just_4_padded = [np.pad(lst, (0, max_len - len(lst)), 'constant', constant_values=0) for lst in just_4]\n",
    "\n",
    "# Convert the padded list of lists to a numpy array\n",
    "just_4_array = np.array(just_4_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap\n",
    "plt.imshow(just_4_array, cmap='hot', interpolation='nearest', aspect=100)\n",
    "plt.colorbar()  # Show color scale\n",
    "plt.gcf().set_figheight(10)\n",
    "plt.gcf().set_figwidth(20)\n",
    "plt.ylabel('Layers')\n",
    "plt.xlabel('Neurons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to get the augmented 4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Show 10 4s\n",
    "list_4s = []\n",
    "for i in range(len(x_test)):\n",
    "    if y_test[i] == 4:\n",
    "        list_4s.append(x_test[i])\n",
    "\n",
    "# plot 10 images with the label 4s\n",
    "fig, axs = plt.subplots(2, 5, figsize=(4, 3)) \n",
    "for i in range(10):\n",
    "    row = i // 5 \n",
    "    col = i % 5  \n",
    "    axs[row, col].imshow(list_4s[i].reshape(28, 28), cmap='gray') \n",
    "    axs[row, col].set_title(f'Label: {4}')  \n",
    "    axs[row, col].axis('off')  \n",
    "plt.tight_layout() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Lets create a dataset of ablated 4s\n",
    "# if not os.path.exists('4_dataset'):\n",
    "#     os.makedirs('4_dataset', exist_ok=True)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "list_4s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 4]\n",
    "ablated_list_4s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 4]\n",
    "\n",
    "def find_best_line(image):\n",
    "    row_sums = [sum(row) for row in image]\n",
    "    max_row_idx = row_sums.index(max(row_sums))\n",
    "    return max_row_idx\n",
    "\n",
    "def ablated4(image, index):\n",
    "    max_row_idx = find_best_line(image)\n",
    "    image = image.reshape(28, 28)\n",
    "    image[:, (max_row_idx-2):] = 0  # Fill between max_row_idx and 27 with black\n",
    "    # np.save('7_dataset/abalated_image_' + str(index), image)\n",
    "\n",
    "# Create the new dataset of stalked 4s\n",
    "for index, image in enumerate(list_4s):\n",
    "    ablated4(image, index)\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "list_4s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to run the destalked 4s through the nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realized this will be easier with 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a directory 7_dataset\n",
    "# if not os.path.exists('7_dataset'):\n",
    "#     os.makedirs('7_dataset', exist_ok=True)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "list_7s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 7]\n",
    "ablated_list_7s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 7]\n",
    "\n",
    "def find_best_line(image):\n",
    "    row_sums = [sum(row) for row in image]\n",
    "    max_row_idx = row_sums.index(max(row_sums))\n",
    "    return max_row_idx\n",
    "\n",
    "def ablated7(image, index):\n",
    "    max_row_idx = find_best_line(image)\n",
    "    image = image.reshape(28, 28)\n",
    "    image[:(max_row_idx+3), :] = 0  # Fill between max_row_idx and 27 with black\n",
    "    image[:17, :13] = 0  # Fill between 0 and 17 with black in the range 0 to 12\n",
    "    # plt.imshow(image, cmap='gray')\n",
    "    # np.save('7_dataset/abalated_image_' + str(index), image)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "list_7s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 7]   \n",
    "\n",
    "for index, image in enumerate(ablated_list_7s):\n",
    "    ablated7(image, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now feed in the ablated 7s and original 7s to the model and predict the class for each then graph that\n",
    "def get4results():\n",
    "    origional_results_4 = []\n",
    "    abalated_results_4 = []\n",
    "\n",
    "    for image in list_4s:\n",
    "        origional_results_4.append(np.argmax(model.predict(image.reshape(1, 784))))\n",
    "    for image in ablated_list_4s:\n",
    "        abalated_results_4.append(np.argmax(model.predict(image.reshape(1, 784))))\n",
    "\n",
    "    return origional_results_4, abalated_results_4\n",
    "\n",
    "def get7results():\n",
    "    origional_results_7 = []\n",
    "    abalated_results_7 = []\n",
    "\n",
    "    for image in list_7s:\n",
    "        origional_results_7.append(np.argmax(model.predict(image.reshape(1, 784))))\n",
    "    for image in ablated_list_7s:\n",
    "        abalated_results_7.append(np.argmax(model.predict(image.reshape(1, 784))))\n",
    "\n",
    "    return origional_results_7, abalated_results_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origional_results_4, ablated_results_4 = get4results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origional_results_7, ablated_results_7 = get7results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the accuracy of the model on the ablated 4s using origional_results_4 and ablated_results_4\n",
    "def numCorrect(data, target, ab):\n",
    "    correct = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i] == target:\n",
    "            correct += 1\n",
    "    if ab:\n",
    "        print(f\"Accuracy on the ablated {target}s: {correct / len(data)}\")\n",
    "    else:\n",
    "        print(f\"Accuracy on the origional {target}s: {correct / len(data)}\")\n",
    "    return correct / len(data)\n",
    "\n",
    "\n",
    "numCorrect(origional_results_4, 4, False)\n",
    "numCorrect(ablated_results_4, 4, True)\n",
    "print(\"------------------------------------------------\")\n",
    "numCorrect(origional_results_7, 7, False)\n",
    "numCorrect(ablated_results_7, 7, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "data = [(origional_results_7, ablated_results_7), (origional_results_4, ablated_results_4)]\n",
    "labels = [('Original 7s', 'Ablated 7s'), ('Original 4s', 'Ablated 4s')]\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    ax.hist(data[i][0], bins=10, color='blue', edgecolor='black', alpha=0.5, label=labels[i][0])\n",
    "    ax.hist(data[i][1], bins=10, color='red', edgecolor='black', alpha=0.5, label=labels[i][1])\n",
    "\n",
    "    ax.set_title(f'{labels[i][0]} vs {labels[i][1]}')\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows the side by side comparison of the ablated 7s and the original 7s\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "list_7s = [x_test[i] for i in range(len(x_test)) if y_test[i] == 7]\n",
    "\n",
    "images = [ablated_list_7s[0], list_7s[0]]\n",
    "\n",
    "for i in range(20):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(ablated_list_7s[i].reshape(28, 28), cmap='gray')\n",
    "    guess1 = np.argmax(model.predict(ablated_list_7s[i].reshape(1, 784)))\n",
    "    plt.title(f\"Class: {guess1}\")\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(list_7s[i].reshape(28, 28), cmap='gray')\n",
    "    guess2 = np.argmax(model.predict(list_7s[i].reshape(1, 784)))\n",
    "    plt.title(f\"Class: {guess2}\")\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
